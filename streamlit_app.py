import streamlit as st
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import pdfplumber

# Configura√ß√£o inicial da p√°gina
st.set_page_config(page_title="PublixBot 1.5", layout="wide")

# Fun√ß√£o para carregar o modelo de embeddings
@st.cache_resource
def load_model():
    try:
        model = SentenceTransformer('all-MiniLM-L6-v2')  # Modelo leve e eficiente
        st.write("Modelo de embeddings carregado com sucesso!")
        return model
    except Exception as e:
        st.error(f"Erro ao carregar o modelo de embeddings: {e}")
        return None

model = load_model()

# Fun√ß√£o para encontrar par√°grafos relevantes
def find_relevant_paragraphs(user_input, paragraphs):
    if model is None:
        return "Erro: O modelo de an√°lise sem√¢ntica n√£o est√° dispon√≠vel."
    
    try:
        # Gera√ß√£o do embedding da consulta do usu√°rio
        query_embedding = model.encode(user_input)
        paragraph_embeddings = [model.encode(p) for p in paragraphs if p.strip()]

        if not paragraph_embeddings:
            return "Erro: N√£o h√° par√°grafos dispon√≠veis para compara√ß√£o."

        # C√°lculo da similaridade
        similarities = cosine_similarity([query_embedding], paragraph_embeddings)
        best_match_idx = similarities.argmax()

        return paragraphs[best_match_idx]

    except Exception as e:
        st.warning(f"Erro na an√°lise sem√¢ntica: {e}")
        return "N√£o foi poss√≠vel processar a an√°lise sem√¢ntica. Tente novamente."

# Fun√ß√£o principal para gerar respostas
def gerar_resposta(texto_usuario):
    if 'paragraphs' not in st.session_state or not st.session_state.paragraphs:
        return "Erro: Nenhum documento carregado ou o texto n√£o foi extra√≠do corretamente."

    # Chama a fun√ß√£o de busca de par√°grafos relevantes
    paragrafo_relevante = find_relevant_paragraphs(texto_usuario, st.session_state.paragraphs)
    return paragrafo_relevante

# Interface principal do app
def main():
    # T√≠tulo e instru√ß√µes
    st.title("PublixBot 1.5")
    st.markdown("Essa √© a intelig√™ncia artificial desenvolvida pelo Instituto Publix. Pergunte qualquer coisa com base no conte√∫do dos documentos!")

    # √Årea de upload de PDF
    uploaded_file = st.file_uploader("Fa√ßa upload de documentos (.pdf)", type=["pdf"])
    if uploaded_file:
        try:
            with pdfplumber.open(uploaded_file) as pdf:
                text = "\n".join(page.extract_text() or '' for page in pdf.pages)
                if text.strip():
                    paragraphs = text.split('\n\n')
                    st.session_state.paragraphs = paragraphs
                    st.success("Documento carregado com sucesso!")
                else:
                    st.error("Erro: O documento PDF n√£o cont√©m texto ou o texto n√£o foi extra√≠do corretamente.")
        except Exception as e:
            st.error(f"Erro ao processar o PDF: {e}")

    # Campo de entrada de perguntas do usu√°rio
    user_input = st.text_input("Digite sua mensagem aqui:")
    if user_input:
        resposta_bot = gerar_resposta(user_input)
        st.markdown(f"**Bot:** {resposta_bot}")

    # Bot√µes de controle
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("Limpar hist√≥rico"):
            st.session_state.paragraphs = []
            st.success("Hist√≥rico limpo com sucesso!")

    with col2:
        if st.button("üìÑ Baixar Resumo"):
            if 'paragraphs' in st.session_state and st.session_state.paragraphs:
                resumo_texto = "\n\n".join(st.session_state.paragraphs)
                st.download_button(label="üì• Clique aqui para baixar", data=resumo_texto, file_name="resumo.txt")
            else:
                st.warning("Nenhum conte√∫do dispon√≠vel para download.")

# Executar o app
if __name__ == '__main__':
    main()
